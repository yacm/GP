{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-parametric and parametric methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think we should come back to the determination of the parton distribution functions assuming the form \n",
    "\\begin{equation}\n",
    "    P(x)=\\Gamma(x)x^\\alpha(1-x)^\\beta\n",
    "\\end{equation}\n",
    "The only contraint we need is the normalization $\\int P(x)dx=1$. The posterior can be calculated in the same way as we did for P(x) but now for $\\Gamma(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch as tr\n",
    "\n",
    "if tr.backends.mps.is_available():\n",
    "    device = tr.device(\"mps\")\n",
    "    x = tr.ones(1, device=device)\n",
    "    print (x)\n",
    "elif tr.cuda.is_available():\n",
    "    device = tr.device(\"cuda\")\n",
    "    x = tr.ones(1, device=device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS or cuda device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GP import *\n",
    "import torch as tr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics as st\n",
    "\n",
    "import scipy.integrate as integrate\n",
    "from torch.special import gammaln\n",
    "#from orthogonal_poly import legendre_01\n",
    "\n",
    "from torch.autograd.functional import hessian\n",
    "\n",
    "import scipy.integrate as integrate\n",
    "\n",
    "import h5py as h5\n",
    "\n",
    "# import all packages and set plots to be embedded inline\n",
    "import numpy as np \n",
    "from scipy.optimize import minimize \n",
    "from scipy import special \n",
    "from scipy.optimize import Bounds \n",
    "from scipy.linalg import cho_solve \n",
    "from pyDOE import lhs \n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.pipeline import Pipeline \n",
    "import torch as tr\n",
    "import scipy.special\n",
    "\n",
    "def get_dist_matelem(z, p, t_min):\n",
    "    f = 0\n",
    "    if p <= 3:\n",
    "        f = h5.File('pdf-data/Nf2+1/ratio.summationLinearFits.cl21_32_64_b6p3_m0p2350_m0p2050.unphased.hdf5','r')\n",
    "    else:\n",
    "        f = h5.File('pdf-data/Nf2+1/ratio.summationLinearFits.cl21_32_64_b6p3_m0p2350_m0p2050.phased-d001_2.00.hdf5','r')\n",
    "    M_z_p = np.array(f['MatElem/bins/Re/mom_0_0_+'+str(p)+'/disp_z+'+str(z)+'/insertion_gt/tsep_'+str(t_min)+'-14'])\n",
    "    M_0_0 = np.array(f['MatElem/bins/Re/mom_0_0_0/disp_0/insertion_gt/tsep_'+str(t_min)+'-14'])\n",
    "    M_z_0 = np.array(f['MatElem/bins/Re/mom_0_0_0/disp_z+'+str(z)+'/insertion_gt/tsep_'+str(t_min)+'-14'])\n",
    "    M_0_p = np.array(f['MatElem/bins/Re/mom_0_0_+'+str(p)+'/disp_0/insertion_gt/tsep_'+str(t_min)+'-14'])\n",
    "    \n",
    "    f.close()\n",
    "    return M_z_p * M_0_0 / M_0_p / M_z_0\n",
    "\n",
    "def get_final_res(z, p):\n",
    "    m_4, _ = get_dist_matelem(z, p, 4)\n",
    "    m_6, s_6 = get_dist_matelem(z, p, 6)\n",
    "    m_8, s_8 = get_dist_matelem(z, p, 8)\n",
    "    return m_6, np.sqrt(s_6**2)#+(m_4-m_6)**2)\n",
    "\n",
    "Np = 6\n",
    "Nz = 12\n",
    "Nj = 349\n",
    "rMj = np.empty([Nj,Np,Nz])\n",
    "nu = np.empty([Np,Nz])\n",
    "for p in range(1,Np+1):\n",
    "    for z in range (1,Nz+1):\n",
    "        nu[p-1,z-1] = 2.0*np.pi/32.0 *p *z\n",
    "        #print(p,z,nu[p-1,z-1])\n",
    "        m_4 = get_dist_matelem(z,p,4)\n",
    "        m_6 = get_dist_matelem(z,p,6)\n",
    "        m_8 = get_dist_matelem(z,p,8)\n",
    "        #expo fit\n",
    "        m = (m_4*m_8 - m_6**2)/(m_4 + m_8 - 2 * m_6)\n",
    "        # this fails for certain cases where the denomenator goes too close to zero\n",
    "        # use the m_6 as default\n",
    "        rMj[:,p-1,z-1] = m_6\n",
    "        #Nj=m.shape[0]\n",
    "        #print(z,p,np.mean(m_4),np.mean(m_6),np.mean(m_8), np.mean(m),np.std(m)*np.sqrt(Nj-1))\n",
    "rM = np.mean(rMj,axis=0)\n",
    "rMe = np.std(rMj,axis=0)*np.sqrt(Nj) \n",
    "#plot the data\n",
    "#for i in range(0,6):\n",
    "#    plt.errorbar(nu[i],rM[i],yerr=rMe[i],fmt='.',alpha=0.5,label='p='+str(i+1))\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "##integrator\n",
    "class FE_Integrator:\n",
    "    def __init__(self,x):\n",
    "        self.N = x.shape[0]\n",
    "        xx = np.append(x,2.0*x[self.N-1] - x[self.N-2])\n",
    "        self.x = np.append(0,xx)\n",
    "        self.eI = 0\n",
    "\n",
    "        self.Norm = np.empty(self.N)\n",
    "        for i in range(self.N):\n",
    "            self.Norm[i] = self.ComputeI(i, lambda x : 1)\n",
    "            \n",
    "    def pulse(self,x,x1,x2):\n",
    "        return np.heaviside(x-x1,0.5)* np.heaviside(x2-x,0.5)\n",
    "    \n",
    "    def f(self,x,i):\n",
    " ##       if(i==0):\n",
    " ##           R=(x- self.x[2])/(self.x[1] -self.x[2])*np.heaviside(x-self.x[0],1.0)* np.heaviside(self.x[2]-x,0.5)\n",
    "\n",
    "            #R= self.pulse(x,self.x[0],self.x[1])\n",
    "            #R= (x- self.x[0])/(self.x[1] -self.x[0])*self.pulse(x,self.x[0],self.x[1])\n",
    "            #R+=(x- self.x[2])/(self.x[1] -self.x[2])*self.pulse(x,self.x[1],self.x[2])\n",
    "            #R+=(x- self.x[1])/(self.x[0] -self.x[1])*self.pulse(x,self.x[0],self.x[1]) \n",
    "##            return R\n",
    "        ii=i+1\n",
    "        R = (x- self.x[ii-1])/(self.x[ii] -self.x[ii-1])*self.pulse(x,self.x[ii-1],self.x[ii  ])\n",
    "        R+= (x- self.x[ii+1])/(self.x[ii] -self.x[ii+1])*self.pulse(x,self.x[ii  ],self.x[ii+1])\n",
    "\n",
    "       # if(i==0):\n",
    "       #     R *=2\n",
    "        return R\n",
    "    \n",
    "    def set_up_integration(self,Kernel = lambda x: 1):\n",
    "        res = np.empty(self.N)\n",
    "        for i in range(self.N):\n",
    "            res[i] = self.ComputeI(i,Kernel)\n",
    "        return res\n",
    "   \n",
    "    # assume symmetrix function F(x,y) = F(y,x)\n",
    "    # for efficiency\n",
    "    def set_up_dbl_integration(self,Kernel = lambda x,y: 1):\n",
    "        res = np.empty([self.N,self.N])\n",
    "        for i in range(self.N):\n",
    "            for j in range(i,self.N):\n",
    "                res[i,j] = self.ComputeIJ(i,j,Kernel)\n",
    "                res[j,i]  = res[i,j]\n",
    "        #res[0,:] *=2\n",
    "        #res[:,0] *=2\n",
    "        return res\n",
    "        \n",
    "    def ComputeI(self,i,Kernel):\n",
    "        I,eI = integrate.quad(lambda x: Kernel(x)*self.f(x,i), self.x[i], self.x[i+2])\n",
    "        self.eI += eI\n",
    "        return I\n",
    "    \n",
    "    def ComputeIJ(self,i,j,Kernel):\n",
    "        I,eI = integrate.dblquad(lambda x,y: self.f(x,i)*Kernel(x,y)*self.f(y,j), self.x[j], self.x[j+2],self.x[i], self.x[i+2])\n",
    "        self.eI += eI\n",
    "        return I\n",
    "    \n",
    "    \n",
    "# quadratic finite elements are more complicated...\n",
    "# ... but now it works!\n",
    "# also I should try the qubic ones too\n",
    "class FE2_Integrator:\n",
    "    def __init__(self,x):\n",
    "        self.N = x.shape[0]\n",
    "        xx = np.append(x,[2.0*x[self.N-1] - x[self.N-2], 3.0*x[self.N-1]-2*x[self.N-2],0] )\n",
    "        #self.x = np.append([-x[0],0],xx)\n",
    "        self.x = np.append(0,xx)\n",
    "        self.eI = 0\n",
    "\n",
    "        self.Norm = np.empty(self.N)\n",
    "        for i in range(self.N):\n",
    "            self.Norm[i] = self.ComputeI(i, lambda x : 1)\n",
    "            \n",
    "    def pulse(self,x,x1,x2):\n",
    "        return np.heaviside(x-x1,0.5)* np.heaviside(x2-x,0.5)\n",
    "    \n",
    "    def f(self,x,i):\n",
    "        R=0.0\n",
    "        if(i==0):\n",
    "            #R=self.pulse(x,self.x[0],self.x[1])\n",
    "            #R=self.pulse(x,self.x[1],self.x[2])\n",
    "        #    R+=(x- self.x[2])/(self.x[1] -self.x[2])*self.pulse(x,self.x[1],self.x[2])\n",
    "\n",
    "            R+=(x- self.x[2])*(x- self.x[3])/((self.x[1] -self.x[3])*(self.x[1] -self.x[2]))**np.heaviside(x-self.x[0],1.0)* np.heaviside(self.x[3]-x,0.5)\n",
    "            #self.pulse(x,self.x[0],self.x[3])\n",
    "            return R\n",
    "        ii =i+1\n",
    "        if(ii%2==0):\n",
    "            R  += (x- self.x[ii-1])*(x- self.x[ii+1])/((self.x[ii] -self.x[ii+1])*(self.x[ii] -self.x[ii-1]))*self.pulse(x,self.x[ii-1],self.x[ii+1])\n",
    "            return R\n",
    "        else:\n",
    "            R += (x- self.x[ii-2])*(x- self.x[ii-1])/((self.x[ii] -self.x[ii-2])*(self.x[ii] -self.x[ii-1]))*self.pulse(x,self.x[ii-2],self.x[ii  ])\n",
    "            R += (x- self.x[ii+1])*(x- self.x[ii+2])/((self.x[ii] -self.x[ii+2])*(self.x[ii] -self.x[ii+1]))*self.pulse(x,self.x[ii  ],self.x[ii+2])\n",
    "            return R\n",
    "    \n",
    "        return R\n",
    "    \n",
    "    def set_up_integration(self,Kernel = lambda x: 1):\n",
    "        res = np.empty(self.N)\n",
    "        for i in range(self.N):\n",
    "            res[i] = self.ComputeI(i,Kernel)\n",
    "        return res\n",
    "        \n",
    "    # assume symmetrix function F(x,y) = F(y,x)\n",
    "    # for efficiency \n",
    "    def set_up_dbl_integration(self,Kernel = lambda x,y: 1):\n",
    "        res = np.empty([self.N,self.N])\n",
    "        for i in range(self.N):\n",
    "            for j in range(i,self.N):\n",
    "                res[i,j] = self.ComputeIJ(i,j,Kernel)\n",
    "                res[j,i]  = res[i,j]\n",
    "        return res\n",
    "    \n",
    "    def ComputeI(self,i,Kernel):\n",
    "        #if(i==0):\n",
    "        #    I,eI = integrate.quad(lambda x: Kernel(x)*self.f(x,0), self.x[0], self.x[3])\n",
    "        #    self.eI += eI\n",
    "        #    return I\n",
    "        ii=i+1\n",
    "        if(ii%2==0):\n",
    "            I,eI = integrate.quad(lambda x: Kernel(x)*self.f(x,i), self.x[ii-1], self.x[ii+1])\n",
    "            self.eI += eI\n",
    "        else:\n",
    "            I,eI = integrate.quad(lambda x: Kernel(x)*self.f(x,i), self.x[ii-2], self.x[ii+2])\n",
    "            self.eI += eI\n",
    "        return I\n",
    "    \n",
    "    def ComputeIJ(self,i,j,Kernel):\n",
    "        # I need to fix the i=0 case\n",
    "        ii=i+1\n",
    "        jj=j+1\n",
    "        if(ii%2==0):\n",
    "            xx = (self.x[ii-1], self.x[ii+1])\n",
    "        else:\n",
    "            xx = (self.x[ii-2], self.x[ii+2])\n",
    "        if(jj%2==0):\n",
    "            yy = (self.x[jj-1], self.x[jj+1])\n",
    "        else:\n",
    "            yy = (self.x[jj-2], self.x[jj+2])\n",
    "        \n",
    "        I,eI = integrate.dblquad(lambda x,y: self.f(x,i)*Kernel(x,y)*self.f(y,j), yy[0], yy[1],xx[0], xx[1])\n",
    "        self.eI += eI\n",
    "\n",
    "        return I\n",
    "\n",
    "def interp(x,q,fe):\n",
    "    S = 0*x\n",
    "    for k in range(fe.N):\n",
    "        S+= fe.f(x,k)*q[k]\n",
    "    return S\n",
    "\n",
    "\n",
    "#### MODELS ####\n",
    "\n",
    "\n",
    "class simple_PDF():\n",
    "    def __init__(self,a,b,g): \n",
    "        self.a=a\n",
    "        self.b=b\n",
    "        self.g=g\n",
    "        self.r = 1.0\n",
    "        self.F = lambda y: (y**a*(1-y)**b*(1 + g*np.sqrt(y)))/self.r\n",
    "        self.r,e = integrate.quad(self.F,0.0,1.0)  \n",
    "\n",
    "\n",
    "def DPDFnormed(x,a,b):\n",
    "    P=tr.tensor([a,b])\n",
    "    a,b=P[0],P[1]\n",
    "    dG_da,dG_db=dNorm(P)\n",
    "    N=tr.exp(gammaln(a+b+2) - gammaln(a+1) - gammaln(b+1))\n",
    "    dP_da=(tr.pow(x,a))*tr.pow(1-x,b)*tr.log(x) *N+dG_da*x**a*(1-x)**b\n",
    "    dP_db= (tr.pow(x,a))*tr.pow(1-x,b)*tr.log(1-x) *N + dG_db*x**a*(1-x)**b\n",
    "    return dP_da,dP_db\n",
    "\n",
    "def Normalization(P):\n",
    "    a,b=P[0],P[1]\n",
    "    return tr.exp(gammaln(a+b+2) - gammaln(a+1) - gammaln(b+1))\n",
    "\n",
    "def dNorm(P):\n",
    "    a,b=P[0],P[1]\n",
    "    dG_da= tr.exp(gammaln(a+b+2) - gammaln(a+1) - gammaln(b+1))*(tr.digamma(a+b+2) - tr.digamma(a+1))\n",
    "    dG_db= tr.exp(gammaln(a+b+2) - gammaln(a+1) - gammaln(b+1))*(tr.digamma(a+b+2) - tr.digamma(b+1))\n",
    "    return tr.tensor([dG_da,dG_db])\n",
    "\n",
    "\n",
    "def simplePDFnormed(x,a,b):\n",
    "    return tr.pow(x,a)*tr.pow(1-x,b)*tr.exp(gammaln(a+b+2) - gammaln(a+1) - gammaln(b+1))\n",
    "#x**a*(1-x)**b*tr.exp(gammaln(a+b+2) - gammaln(a+1) - gammaln(b+1))\n",
    "\n",
    "\n",
    "def very_simplePDFnormed(x,b):\n",
    "    return (1-x)**b*tr.exp(gammaln(b+2) - gammaln(b+1))\n",
    "\n",
    "# Posterior GP V2 with split RBF kernel\n",
    "def pseudo_data(nu,a,b,g,da,db,dg,N):\n",
    "    sa = np.random.normal(a,da,N)\n",
    "    sb = np.random.normal(b,db,N)\n",
    "    sg = np.random.normal(g,dg,N)\n",
    "\n",
    "    D = np.zeros((N,nu.shape[0]))\n",
    "    Norm=1.0\n",
    "    for k in range(N):\n",
    "        for i in range(nu.shape[0]):\n",
    "            F =  lambda y: y**sa[k]*(1-y)**sb[k]*(1 + sg[k]*np.sqrt(y)-0.1*y)*np.cos(nu[i]*y) \n",
    "            r,e = integrate.quad(F,0.0,1.0) \n",
    "            D[k,i] = r\n",
    "            if i==0:\n",
    "                Norm = r\n",
    "            D[k,i] = D[k,i]/Norm\n",
    "    #add additional gaussian noise to break correlations\n",
    "    NN = np.random.normal(0,1e-2,np.prod(D.shape)).reshape(D.shape)\n",
    "    return D+NN\n",
    "\n",
    "def autograd(func,x):\n",
    "    x_tensor = x.clone().detach()\n",
    "    x_tensor.requires_grad_()\n",
    "    y = func(x_tensor)\n",
    "    y.backward()\n",
    "    return x_tensor.grad\n",
    "\n",
    "def DPDFnormed(x,a,b):\n",
    "    P=tr.tensor([a,b])\n",
    "    a,b=P[0],P[1]\n",
    "    dG_da,dG_db=dNorm(P)\n",
    "    N=tr.exp(gammaln(a+b+2) - gammaln(a+1) - gammaln(b+1))\n",
    "    dP_da=(tr.pow(x,a))*tr.pow(1-x,b)*tr.log(x) *N+dG_da*x**a*(1-x)**b\n",
    "    dP_db= (tr.pow(x,a))*tr.pow(1-x,b)*tr.log(1-x) *N + dG_db*x**a*(1-x)**b\n",
    "    return dP_da,dP_db\n",
    "\n",
    "def Normalization(P):\n",
    "    a,b=P[0],P[1]\n",
    "    return tr.exp(gammaln(a+b+2) - gammaln(a+1) - gammaln(b+1))\n",
    "\n",
    "def dNorm(P):\n",
    "    a,b=P[0],P[1]\n",
    "    dG_da= tr.exp(gammaln(a+b+2) - gammaln(a+1) - gammaln(b+1))*(tr.digamma(a+b+2) - tr.digamma(a+1))\n",
    "    dG_db= tr.exp(gammaln(a+b+2) - gammaln(a+1) - gammaln(b+1))*(tr.digamma(a+b+2) - tr.digamma(b+1))\n",
    "    return tr.tensor([dG_da,dG_db])\n",
    "\n",
    "\n",
    "def simplePDFnormed(x,a,b,N):\n",
    "    return N*tr.pow(x,a)*tr.pow(1-x,b)*tr.exp(gammaln(a+b+2) - gammaln(a+1) - gammaln(b+1))\n",
    "\n",
    "#xtensor=tr.tensor(x_grid)\n",
    "def model(x):\n",
    "    a=x[0]\n",
    "    b=x[1]\n",
    "    xtensor=tr.tensor([0.5])\n",
    "    return simplePDFnormed(xtensor,a,b)\n",
    "\n",
    "#### Kernels #####\n",
    "\n",
    "def KrbfMat(x,s,w):\n",
    "    xx=x.view(1,x.shape[0])\n",
    "    yy=x.view(x.shape[0],1)\n",
    "    return s*s*tr.exp(-0.5*((xx - yy)/w)**2)\n",
    "\n",
    "def Krbf_no_s(x,w):\n",
    "    xx=x.view(1,x.shape[0])\n",
    "    yy=x.view(x.shape[0],1)\n",
    "    return tr.exp(-0.5*((xx - yy)/w)**2)\n",
    "\n",
    "\n",
    "def Krbf1(x,s,w):\n",
    "    xx=x.view(1,x.shape[0])\n",
    "    yy=x.view(x.shape[0],1)\n",
    "    w=10**w\n",
    "    s=10**s\n",
    "    return s**2*tr.exp(-0.5*((xx - yy)/w)**2)\n",
    "\n",
    "\n",
    "class splitRBFker():\n",
    "    def __init__(self,sp,scale=1):\n",
    "        self.sp =sp\n",
    "        self.scale = scale\n",
    "    def KerMat(self,x,s1,w1,s2,w2):\n",
    "        K2 = KrbfMat(x,s2,w2) # linear\n",
    "        K1 = KrbfMat(tr.log(x),s1,w1)\n",
    "        sig = tr.diag(tr.special.expit(self.scale*(x-self.sp)))\n",
    "        sigC = tr.eye(x.shape[0])-sig\n",
    "        ##return K1+K2\n",
    "        return sigC@K2@sigC + sig@K1@sig\n",
    "\n",
    "def Sig(x,scale,sp=0.1):\n",
    "    return tr.special.expit(scale*(x-sp))\n",
    "def transform(s):\n",
    "    return s.view(s.shape[1],1).repeat(1,s.shape[1])\n",
    "\n",
    "#  write the last one as a function\n",
    "def splitRBFkerMat(x,s1,w1,s2,w2,scale,sp=0.1,eps=1e-12):\n",
    "    #plot this values and it looks like a simple rbf kernel\n",
    "    #s1,w1,s2,w2,scale,sp =  1.0,0.1,1.0,2.2,1.0,.1\n",
    "    K1 = KrbfMat(x,s1,w1) # linear\n",
    "    K2 = KrbfMat(tr.log(x+eps),s2,w2) #log\n",
    "    xx=x.view(1,x.shape[0])\n",
    "    ss=Sig(xx,scale,sp)\n",
    "    s=transform(ss)\n",
    "    #sig=sig.view(1,sig.shape[1]).repeat(sig.shape[1],1)\n",
    "    sC = 1-s\n",
    "    return  s*K1*s.T +sC*K2*sC.T\n",
    "\n",
    "def splitRBF1(x,s1,w1,s2,w2,scale,sp=0.1,eps=1e-12):\n",
    "    #plot this values and it looks like a simple rbf kernel\n",
    "    #s1,w1,s2,w2,scale,sp =  1.0,0.1,1.0,2.2,1.0,.1\n",
    "    K1 = Krbf1(x,s1,w1) # linear\n",
    "    K2 = Krbf1(tr.log(x+eps),s2,w2) #log\n",
    "    xx=x.view(1,x.shape[0])\n",
    "    ss=Sig(xx,scale,sp)\n",
    "    s=transform(ss)\n",
    "    #sig=sig.view(1,sig.shape[1]).repeat(sig.shape[1],1)\n",
    "    sC = 1-s\n",
    "    return  s*K1*s.T +sC*K2*sC.T\n",
    "\n",
    "#DERIVATIVES\n",
    "def Krbf_ds(x,s,w):\n",
    "    xx=x.view(1,x.shape[0])\n",
    "    yy=x.view(x.shape[0],1)\n",
    "    return 2*s*tr.exp(-0.5*((xx - yy)/w)**2)\n",
    "    #return  2*s*tr.exp(-0.5*((x.view(1,x.shape[0]) - x.view(x.shape[0],1))/w)**2)\n",
    "def Krbf_dw(x,s,w):\n",
    "    xx=x.view(1,x.shape[0])\n",
    "    yy=x.view(x.shape[0],1)\n",
    "    return s*s*tr.exp(-0.5*((xx - yy)/w)**2)*(xx-yy)**2/((w**3))\n",
    "\n",
    "def sig_ds(x,scale,sp=0.1):\n",
    "    sig = tr.special.expit(scale*(x.view(1,x.shape[0])-sp))\n",
    "    return sig*(1-sig)\n",
    "\n",
    "def Kcom_ds1(x,s1,w1,s2,w2,scale,sp=0.1,eps=1e-12):\n",
    "    sig = tr.special.expit(scale*(x.view(1,x.shape[0])-sp))\n",
    "    sig=sig.view(sig.shape[1],1).repeat(1,sig.shape[1])\n",
    "    #sigC = 1-sig\n",
    "    return sig*Krbf_ds(x,s1,w1)*sig.T\n",
    "def Kcom_dw1(x,s1,w1,s2,w2,scale,sp=0.1,eps=1e-12):\n",
    "    sig = tr.special.expit(scale*(x.view(1,x.shape[0])-sp))\n",
    "    sig=sig.view(sig.shape[1],1).repeat(1,sig.shape[1])\n",
    "    #sigC = 1-sig\n",
    "    return sig*Krbf_dw(x,s1,w1)*sig.T\n",
    "def Kcom_ds2(x,s1,w1,s2,w2,scale,sp=0.1,eps=1e-15):\n",
    "    sig = tr.special.expit(scale*(x.view(1,x.shape[0])-sp))\n",
    "    sig=sig.view(sig.shape[1],1).repeat(1,sig.shape[1])\n",
    "    sigC = 1-sig\n",
    "    return sigC*Krbf_ds(tr.log(x+eps),s2,w2)*sigC.T\n",
    "def Kcom_dw2(x,s1,w1,s2,w2,scale,sp=0.1,eps=1e-12):\n",
    "    sig = tr.special.expit(scale*(x.view(1,x.shape[0])-sp))\n",
    "    sig=sig.view(sig.shape[1],1).repeat(1,sig.shape[1])\n",
    "    sigC = 1-sig\n",
    "    return sigC*Krbf_dw(tr.log(x+eps),s2,w2)*sigC.T\n",
    "\n",
    "def sig_ds(x,scale,sp=0.1):\n",
    "    return tr.exp(-scale*(x-sp))*(x-sp)*tr.special.expit(scale*(x-sp))**2\n",
    "\n",
    "def Kcom_ds(x,s1,w1,s2,w2,scale,sp=0.1,eps=1e-12):\n",
    "    K2=KrbfMat(tr.log(x+eps),s2,w2)\n",
    "    K1=KrbfMat(x,s1,w1)\n",
    "    xx=x.view(1,x.shape[0])\n",
    "    yy=x.view(x.shape[0],1)\n",
    "    ##vectors\n",
    "    ssx=Sig(xx,scale,sp)\n",
    "    ssy=Sig(yy,scale,sp)\n",
    "    #transform into matrix\n",
    "    sx=transform(ssx)\n",
    "    sy=transform(ssy.T)\n",
    "\n",
    "    dssx=sig_ds(xx,scale,sp)\n",
    "    dssy=sig_ds(yy,scale,sp)\n",
    "    #transform into matrix\n",
    "    dsx=transform(dssx)\n",
    "    dsy=transform(dssy.T)\n",
    "\n",
    "    F1=((-1+sy.T)*dsx + (sx-1)*dsy.T)*K2\n",
    "    F2=((dsx)*sy.T + sx*(dsy.T))*K1\n",
    "    return F1+F2\n",
    "\n",
    "def R(z,t):\n",
    "    return 1.0/tr.sqrt(1-2*z*t+t*t)\n",
    "\n",
    "def jacobi(x,s,t,a,b):\n",
    "   x=x.view(x.shape[0],1)\n",
    "   y=x.view(1,x.shape[0])\n",
    "   return (s**2)*(x*y)**a*((1-x)*(1-y))**b*(R(2*x-1,t)*R(2*y-1,t)*((1-t+R(2*x-1,t))*(1-t+R(2*y-1,t)))**a*((1+t+R(2*x-1,t))*(1+t+R(2*y-1,t)))**b)**(-1)#+1e-6*tr.eye(x.shape[0])\n",
    "   #return s*(x.view(1,x.shape[0])*x.view(x.shape[0],1))**a*((1-x.view(1,x.shape[0]))*(1-x.view(x.shape[0],1)))**b*(R(2*x.view(1,x.shape[0])-1,t)*R(2*x.view(x.shape[0],1)-1,t)*((1-t+R(2*x.view(1,x.shape[0])-1,t))*(1-t+R(2*x.view(x.shape[0],1)-1,t)))**a*((1+t+R(2*x.view(1,x.shape[0])-1,t))*(1+t+R(2*x.view(x.shape[0],1)-1,t)))**b)**(-1)\n",
    "\n",
    "#plot the trace1\n",
    "def plothist(trace,mygp1,disc,params=\"model+kernel+noise\",prior=False,burn=100,kernel='jacobi'):\n",
    "    fig, ax = plt.subplots(trace.shape[1], 1, figsize=(10, 10), sharex=False, sharey=False)\n",
    "\n",
    "    mygp=mygp1\n",
    "\n",
    "    i0 = 100\n",
    "    iF=10000\n",
    "    if kernel=='jacobi':\n",
    "        lab=['α', 'β', 'N','s', 't', 'a', 'b','σerror']\n",
    "        labprior=['α-prior', 'β-prior', 's-prior', 't-prior', 'a-prior', 'b-prior','σerror-prior']\n",
    "        if params==\"kernel\":\n",
    "            lab=lab[mygp.Npd_args:]\n",
    "            mygp.prior_dist=mygp.prior_dist[mygp.Npd_args:]\n",
    "        elif params==\"kernel+noise\":\n",
    "            lab=lab[mygp.Npd_args:]\n",
    "            mygp.prior_dist=mygp.prior_dist[mygp.Npd_args:]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    elif kernel=='combinedRBF':\n",
    "        lab=['α','β','N','σ1','w1','σ2','w2','s','σnoise']\n",
    "        labprior=['α-prior','β-prior','σ1-prior','w1-prior','σ2-prior','w2-prior','s-prior','σerror-prior']\n",
    "        if params==\"kernel\":\n",
    "            lab=lab[mygp.Npd_args:]\n",
    "            mygp.prior_dist=mygp.prior_dist[mygp.Npd_args:]\n",
    "        elif params==\"kernel+noise\":\n",
    "            lab=lab[mygp.Npd_args:]\n",
    "            mygp.prior_dist=mygp.prior_dist[mygp.Npd_args:]\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    elif kernel=='RBF':\n",
    "        lab=['α','β','N','σ','w','σnoise']\n",
    "        labprior=['α-prior','β-prior','σ-prior','w-prior','σerror-prior']\n",
    "        if params==\"kernel\":\n",
    "            lab=lab[mygp.Npd_args:]\n",
    "            mygp.prior_dist=mygp.prior_dist[mygp.Npd_args:]\n",
    "        elif params==\"kernel+noise\":\n",
    "            lab=lab[mygp.Npd_args:]\n",
    "            mygp.prior_dist=mygp.prior_dist[mygp.Npd_args:]\n",
    "        else:\n",
    "            pass\n",
    "    elif kernel=='model':\n",
    "        lab=['α','β']\n",
    "        labprior=['α-prior','β-prior']\n",
    "    else:\n",
    "        #parameters in greek\n",
    "        lab=['α','β','γ','δ','ε','ζ','η','θ','ι','κ','λ','μ','ν','ξ','ο','π','ρ','σ','τ','υ','φ','χ','ψ','ω']\n",
    "        labprior=['α-prior','β-prior','γ-prior','δ-prior','ε-prior','ζ-prior','η-prior','θ-prior','ι-prior','κ-prior','λ-prior','μ-prior','ν-prior','ξ-prior','ο-prior','π-prior','ρ-prior','σ-prior','τ-prior','υ-prior','φ-prior','χ-prior','ψ-prior','ω-prior']\n",
    "\n",
    "    col=['red','blue','green','pink','black','orange','purple','brown','yellow','cyan','magenta','grey',\"lightblue\",\"lightgreen\",\"lightcoral\",\"lightpink\",\"lightyellow\",\"lightcyan\",\"lightmagenta\",\"lightgrey\",\"darkblue\",\"darkgreen\",\"darkcoral\",\"darkpink\",\"darkyellow\",\"darkcyan\",\"darkmagenta\",\"darkgrey\"]\n",
    "    for i in range(trace.shape[1]):\n",
    "        ax[i].hist(trace[i0:iF,i],bins=disc,label=lab[i],color=col[i],density=True)\n",
    "        if prior:\n",
    "            initial=mygp.prior_dist[i].shift\n",
    "            final=mygp.prior_dist[i].shift+mygp.prior_dist[i].scale\n",
    "            xxx = tr.linspace(initial,final,1000)\n",
    "            distexp=mygp.prior_dist[i]\n",
    "            pdfs=tr.zeros(xxx.shape[0])\n",
    "            for k in range(xxx.shape[0]):\n",
    "                pdfs[k]=distexp.pdf(xxx[k])\n",
    "            ax[i].plot(xxx,pdfs.detach().numpy())\n",
    "            ax[i].set_xlim([initial-0.5,final+0.5])\n",
    "        ax[i].legend()\n",
    "    plt.show()\n",
    "def plotrace(trace,burn=100,kernel='jacobi'):\n",
    "    fig, ax = plt.subplots(trace.shape[1],figsize=(20, 8))\n",
    "    i0 = burn\n",
    "    iF=trace.shape[0]\n",
    "    if kernel=='jacobifull':\n",
    "        lab=['α','β','N','s','t','a','b']\n",
    "    elif kernel=='rbf':\n",
    "        lab=['α','β','N','σ','w','σnoise']\n",
    "    else:\n",
    "        lab=['α', 'β','N','σ1','w1','σ2','w2','s','σnoise']\n",
    "    col=['red','blue','green','pink','black','orange','purple','brown','grey',\"lightblue\",\"lightgreen\",\"lightcoral\",\"lightpink\",\"lightyellow\",\"lightcyan\",\"lightmagenta\",\"lightgrey\",\"darkblue\",\"darkgreen\",\"darkcoral\",\"darkpink\",\"darkyellow\",\"darkcyan\",\"darkmagenta\",\"darkgrey\"]\n",
    "    for i in range(trace.shape[1]):\n",
    "        ax[i].plot(trace[i0:iF,i],label=lab[i],color=col[i])\n",
    "        ax[i].legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def RBF(x,s,w):\n",
    "    return s*s*tr.exp(-0.5*((x.view(1,x.shape[0]) - x.view(x.shape[0],1))/w)**2)\n",
    "\n",
    "\n",
    "#from tensor to list\n",
    "def tensor2list(tensor):\n",
    "    return [tensor[i].item() for i in range(tensor.shape[0])]\n",
    "\n",
    "Nx=256\n",
    "x_grid = np.concatenate((np.logspace(-12,-1,np.int32(Nx/2)),np.linspace(0.1+1e-4,1-1e-12,np.int32(Nx/2))))\n",
    "\n",
    "#mockdata\n",
    "\n",
    "\n",
    "#set up input data\n",
    "def preparedata(i,nu,rMj,rMe,rM,scale=\"log\"):\n",
    "    #prepare the data\n",
    "    Nnu = nu.shape[1]\n",
    "    CovD= np.corrcoef(rMj[:,:,i-1].T)#*(rMj[:,:,i-1].T.shape[0]-1)\n",
    "    CovD =tr.tensor( (CovD + CovD.T)/2)\n",
    "    M = rM.T[i]\n",
    "    eM = rMe.T[i]\n",
    "    n = nu.T[i]\n",
    "    Nx=256\n",
    "    if scale==\"lin\":\n",
    "        x_grid = np.linspace(0.0+1e-12,1-1e-12,np.int32(Nx))\n",
    "    elif scale==\"log\":\n",
    "        x_grid = np.concatenate((np.logspace(-12,-1,np.int32(Nx/2)),np.linspace(0.1+1e-4,1-1e-12,np.int32(Nx/2))))\n",
    "    #x_grid = np.concatenate((np.logspace(-12,-1,np.int32(Nx/2)),np.linspace(0.1+1e-4,1-1e-12,np.int32(Nx/2))))\n",
    "    fe = FE2_Integrator(x_grid)\n",
    "    # soften the constrants\n",
    "    lam = 1e-5  #normalization\n",
    "    lam_c = 1e-5 #x=1 \n",
    "    B0 = fe.set_up_integration(Kernel=lambda x: 1)\n",
    "    B1 = np.zeros_like(B0) \n",
    "    B1[-1] = 1.0 # x=1 is at the end...\n",
    "    n # is the nu values at current z\n",
    "    B = np.zeros((n.shape[0],Nx))\n",
    "    for k in np.arange(n.shape[0]):\n",
    "        B[k,:] = fe.set_up_integration(Kernel= lambda x : np.cos(n[k]*x))\n",
    "    V = np.concatenate((B0[np.newaxis,:],B1[np.newaxis,:],B))\n",
    "    Gamma = np.zeros((V.shape[0],V.shape[0]))\n",
    "    Gamma[0,0] = lam\n",
    "    Gamma[1,1] = lam_c\n",
    "    Gamma[2:,2:] = CovD\n",
    "    Y = np.concatenate(([1,0],M))\n",
    "    return x_grid,V,Y,Gamma\n",
    "\n",
    "def preparemockdata(Nnupoints):\n",
    "    #MOCK data\n",
    "    #######Generate mock data to test the GP\n",
    "\n",
    "    numock = np.linspace(0,13,Nnupoints)\n",
    "    #create fake data\n",
    "    #a,b,c\n",
    "    jM = pseudo_data(numock,-0.3,2.9,1.0,0.02,.2,0.2,1000)\n",
    "    #print(jM.shape)\n",
    "    M = np.mean(jM,axis=0)\n",
    "    eM = np.std(jM,axis=0)\n",
    "    \"\"\"print(\"Check the zero point:\",nu[0],M[0],eM[0])\n",
    "    plt.errorbar(numock,M,eM,marker='o')\n",
    "    plt.show()\"\"\"\n",
    "    #chop off the nu = 0\n",
    "    jM = jM[:,1:]\n",
    "    n = numock[1:]\n",
    "    M = np.mean(jM,axis=0)\n",
    "    eM = np.std(jM,axis=0)\n",
    "\n",
    "    \n",
    "    #print(\"jM shape: \",jM.shape)\n",
    "\n",
    "    CovD = np.corrcoef(jM.T)   \n",
    "    CovD =(CovD + CovD.T)/2.0\n",
    "    \"\"\"U,S,V = np.linalg.svd(CovD)\n",
    "    #print(\"Data Cov: \",CovD)\n",
    "    print(\"Data Cov S:\",S)\n",
    "    #plot covD\n",
    "    plt.imshow(CovD)\n",
    "    plt.show()\"\"\"\n",
    "\n",
    "    Nx=256\n",
    "    x_grid = np.concatenate((np.logspace(-12,-1,np.int32(Nx/2)),np.linspace(0.1+1e-4,1-1e-12,np.int32(Nx/2))))\n",
    "    fe = FE2_Integrator(x_grid)\n",
    "    lam = 1e-7   # soften the constrants\n",
    "    lam_c = 1e-7\n",
    "    B0 = fe.set_up_integration(Kernel=lambda x: 1)\n",
    "    B1 = np.zeros_like(B0) \n",
    "    B1[-1] = 1.0 # x=1 is at the end...\n",
    "    n # is the nu values at current z\n",
    "    B = np.zeros((n.shape[0],Nx))\n",
    "    for k in np.arange(n.shape[0]):\n",
    "        B[k,:] = fe.set_up_integration(Kernel= lambda x : np.cos(n[k]*x))\n",
    "    V = np.concatenate((B0[np.newaxis,:],B1[np.newaxis,:],B))\n",
    "    Gamma = np.zeros((V.shape[0],V.shape[0]))\n",
    "    Gamma[0,0] = lam\n",
    "    Gamma[1,1] = lam_c\n",
    "    Gamma[2:,2:] = CovD\n",
    "    Y = np.concatenate(([1,0],M))\n",
    "    return x_grid,V,Y,Gamma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
