no change     /sciclone/apps/miniforge3-24.9.2-0/condabin/conda
no change     /sciclone/apps/miniforge3-24.9.2-0/bin/conda
no change     /sciclone/apps/miniforge3-24.9.2-0/bin/conda-env
no change     /sciclone/apps/miniforge3-24.9.2-0/bin/activate
no change     /sciclone/apps/miniforge3-24.9.2-0/bin/deactivate
no change     /sciclone/apps/miniforge3-24.9.2-0/etc/profile.d/conda.sh
no change     /sciclone/apps/miniforge3-24.9.2-0/etc/fish/conf.d/conda.fish
no change     /sciclone/apps/miniforge3-24.9.2-0/shell/condabin/Conda.psm1
no change     /sciclone/apps/miniforge3-24.9.2-0/shell/condabin/conda-hook.ps1
no change     /sciclone/apps/miniforge3-24.9.2-0/lib/python3.12/site-packages/xontrib/conda.xsh
no change     /sciclone/apps/miniforge3-24.9.2-0/etc/profile.d/conda.csh
no change     /sciclone/home/yacahuanamedra/.bashrc
No action taken.
Python path: /sciclone/home/yacahuanamedra/.conda/envs/gptorch/bin/python3
Python 3.12.2
Running on node: fm02.sciclone.wm.edu
Running on CPUs: fm02
SLURM job ID: 1608184
SLURM job name: PDF_jacobi_t(kernel+lin)
In directory: /sciclone/scr-lst/yacahuanamedra/GP
Starting Python at Thu May 29 06:51:11 PM EDT 2025
Starting GP
Using device: cpu
Checkpoint 2: imports done
sys.argv: ['run_IS.py', '--mean', 'PDF', '--ker', 'jacobi_t', '--mode', 'kernel', '--grid', 'lin']
Using mean model: PDF, kernel model: jacobi_t, mode: kernel, grid: lin
/sciclone/home/yacahuanamedra/.conda/envs/gptorch/lib/python3.12/site-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1724789563135/work/aten/src/ATen/native/TensorShape.cpp:3609.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/sciclone/home/yacahuanamedra/.conda/envs/gptorch/lib/python3.12/site-packages/torchquad/integration/utils.py:248: UserWarning: DEPRECATION WARNING: In future versions of torchquad, an array-like object will be returned.
  warnings.warn(
#################Define the model###########################
Current date and time : 2025-05-29 18:51:27
GP specifications 
 Sampling or training: kernel
 model: PDF
 kernel: jacobi_t nugget: no
 Ioffe time Distribution: Re(M) 
 mean = tensor([0., 0., 0.]) 
 sigma = tensor([15., 15., 15.]) 
 prior dist = tensor([2, 2, 2]) 
 model init = (0.0, 1.0, 2.0) 
 kernel init = (2.5, 1.0, 1.0) 
 device = cpu 
 mode = kernel 
 ID = 12
z=NNPDF(4) done
z=NNPDF(10) done
z=NNPDF(25) done
#################Define the model###########################
Current date and time : 2025-05-29 18:51:40
GP specifications 
 Sampling or training: kernel
 model: PDF
 kernel: jacobi_t nugget: no
 Ioffe time Distribution: Im(M) 
 mean = tensor([0., 0., 0.]) 
 sigma = tensor([15., 15., 15.]) 
 prior dist = tensor([2, 2, 2]) 
 model init = (0.0, 1.0, 2.0) 
 kernel init = (2.5, 1.0, 1.0) 
 device = cpu 
 mode = kernel 
 ID = 12
z=NNPDF(4) done
z=NNPDF(10) done
z=NNPDF(25) done
Checkpoint 3: Model definitions done
Checkpoint 4: Training models
/sciclone/scr-lst/yacahuanamedra/GP/GP.py:492: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1724789563135/work/aten/src/ATen/native/TensorShape.cpp:3697.)
  nlp= 0.5*(X@X.T+ 2*tr.logdet(L))
Training mean only z=1a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5000e+00,  1.0000e+00,
         1.0000e+00,  1.0000e+00])
Training mean only z=2a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5000e+00,  1.0000e+00,
         1.0000e+00,  1.0000e+00])
Training mean only z=3a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5000e+00,  1.0000e+00,
         1.0000e+00,  1.0000e+00])
Training mean only z=4a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5000e+00,  1.0000e+00,
         1.0000e+00,  1.0000e+00])
Training mean only z=5a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5000e+00,  1.0000e+00,
         1.0000e+00,  1.0000e+00])
Training mean only z=6a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5000e+00,  1.0000e+00,
         1.0000e+00,  1.0000e+00])
Training mean only z=7a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5000e+00,  1.0000e+00,
         1.0000e+00,  1.0000e+00])
Training mean only z=8a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5000e+00,  1.0000e+00,
         1.0000e+00,  1.0000e+00])
Training mean only z=9a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5000e+00,  1.0000e+00,
         1.0000e+00,  1.0000e+00])
Training mean only z=10a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5000e+00,  1.0000e+00,
         1.0000e+00,  1.0000e+00])
Training mean only z=11a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5000e+00,  1.0000e+00,
         1.0000e+00,  1.0000e+00])
Training mean only z=12a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5000e+00,  1.0000e+00,
         1.0000e+00,  1.0000e+00])
Training mean only z=NNPDF(4)
tensor([-0.1759,  1.6570,  2.4903,  2.5000,  1.0000,  1.0000,  1.0000])
Training mean only z=NNPDF(10)
tensor([-0.1888,  1.5746,  2.4203,  2.5000,  1.0000,  1.0000,  1.0000])
Training mean only z=NNPDF(25)
tensor([-0.2230,  1.4580,  2.2155,  2.5000,  1.0000,  1.0000,  1.0000])
time 37.934855937957764
Training kernel only z=1a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,         nan,         nan,
                nan,  1.0000e+00])
Training kernel only z=2a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,         nan,         nan,
                nan,  1.0000e+00])
Training kernel only z=3a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,         nan,         nan,
                nan,  1.0000e+00])
Training kernel only z=4a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,         nan,         nan,
                nan,  1.0000e+00])
Training kernel only z=5a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,         nan,         nan,
                nan,  1.0000e+00])
Training kernel only z=6a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,         nan,         nan,
                nan,  1.0000e+00])
Training kernel only z=7a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,         nan,         nan,
                nan,  1.0000e+00])
Training kernel only z=8a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.4999e+00,  9.9990e-01,
         1.0001e+00,  1.0000e+00])
Training kernel only z=9a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.4999e+00,  9.9990e-01,
         1.0001e+00,  1.0000e+00])
Training kernel only z=10a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.4999e+00,  1.0001e+00,
         1.0001e+00,  1.0000e+00])
Training kernel only z=11a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.4999e+00,  1.0001e+00,
         1.0001e+00,  1.0000e+00])
Training kernel only z=12a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.4999e+00,  1.0001e+00,
         1.0001e+00,  1.0000e+00])
Training kernel only z=NNPDF(4)
tensor([-0.1759,  1.6570,  2.4903,  4.9552,  0.9365,  0.9583,  1.0000])
Training kernel only z=NNPDF(10)
tensor([-0.1888,  1.5746,  2.4203,  5.6744,  0.9882,  0.9896,  1.0000])
Training kernel only z=NNPDF(25)
tensor([-0.2230,  1.4580,  2.2155,  6.2849,  1.1124,  1.0255,  1.0000])
time 42.90062403678894
Checkpoint 4.1: Training Re model done
Training mean only z=1a
tensor([1.0000e-04, 1.0001e+00, 1.9999e+00, 2.5000e+00, 1.0000e+00, 1.0000e+00,
        1.0000e+00])
Training mean only z=2a
tensor([-1.0000e-04,  1.0001e+00,  1.9999e+00,  2.5000e+00,  1.0000e+00,
         1.0000e+00,  1.0000e+00])
Training mean only z=3a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5000e+00,  1.0000e+00,
         1.0000e+00,  1.0000e+00])
Training mean only z=4a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5000e+00,  1.0000e+00,
         1.0000e+00,  1.0000e+00])
Training mean only z=5a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5000e+00,  1.0000e+00,
         1.0000e+00,  1.0000e+00])
Training mean only z=6a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5000e+00,  1.0000e+00,
         1.0000e+00,  1.0000e+00])
Training mean only z=7a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5000e+00,  1.0000e+00,
         1.0000e+00,  1.0000e+00])
Training mean only z=8a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5000e+00,  1.0000e+00,
         1.0000e+00,  1.0000e+00])
Training mean only z=9a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5000e+00,  1.0000e+00,
         1.0000e+00,  1.0000e+00])
Training mean only z=10a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5000e+00,  1.0000e+00,
         1.0000e+00,  1.0000e+00])
Training mean only z=11a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5000e+00,  1.0000e+00,
         1.0000e+00,  1.0000e+00])
Training mean only z=12a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5000e+00,  1.0000e+00,
         1.0000e+00,  1.0000e+00])
Training mean only z=NNPDF(4)
tensor([-0.0105,  1.8799,  2.7904,  2.5000,  1.0000,  1.0000,  1.0000])
Training mean only z=NNPDF(10)
tensor([-0.0640,  1.7074,  2.8182,  2.5000,  1.0000,  1.0000,  1.0000])
Training mean only z=NNPDF(25)
tensor([-0.2450,  1.4736,  1.9918,  2.5000,  1.0000,  1.0000,  1.0000])
time 37.254525661468506
Training kernel only z=1a
tensor([1.0000e-04, 1.0001e+00, 1.9999e+00, 2.5001e+00, 9.9990e-01, 9.9990e-01,
        1.0000e+00])
Training kernel only z=2a
tensor([-1.0000e-04,  1.0001e+00,  1.9999e+00,  2.5001e+00,  1.0001e+00,
         9.9990e-01,  1.0000e+00])
Training kernel only z=3a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5001e+00,  1.0001e+00,
         9.9990e-01,  1.0000e+00])
Training kernel only z=4a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5001e+00,  1.0001e+00,
         9.9990e-01,  1.0000e+00])
Training kernel only z=5a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5001e+00,  1.0001e+00,
         9.9990e-01,  1.0000e+00])
Training kernel only z=6a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5001e+00,  1.0001e+00,
         9.9990e-01,  1.0000e+00])
Training kernel only z=7a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5001e+00,  1.0001e+00,
         9.9990e-01,  1.0000e+00])
Training kernel only z=8a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5001e+00,  1.0001e+00,
         9.9990e-01,  1.0000e+00])
Training kernel only z=9a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5001e+00,  1.0001e+00,
         9.9990e-01,  1.0000e+00])
Training kernel only z=10a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.5001e+00,  1.0001e+00,
         9.9990e-01,  1.0000e+00])
Training kernel only z=11a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.4999e+00,  1.0001e+00,
         9.9990e-01,  1.0000e+00])
Training kernel only z=12a
tensor([-1.0000e-04,  1.0001e+00,  2.0001e+00,  2.4999e+00,  1.0001e+00,
         9.9990e-01,  1.0000e+00])
Training kernel only z=NNPDF(4)
tensor([-0.0105,  1.8799,  2.7904,  3.6626,  0.9079,  0.9653,  1.0000])
Training kernel only z=NNPDF(10)
tensor([-0.0640,  1.7074,  2.8182,  6.8588,  1.3984,  1.0811,  1.0000])
Training kernel only z=NNPDF(25)
tensor([-0.2450,  1.4736,  1.9918,  7.8347,  1.9606,  1.0252,  1.0000])
time 46.99426531791687
Checkpoint 4.2: Training Im model done
Nans in the parameters
Nans in the parameters
Nans in the parameters
Nans in the parameters
Nans in the parameters
Nans in the parameters
Nans in the parameters
Posterior 2nd level minimized
Posterior 2nd level minimized
Posterior 2nd level minimized
Posterior 2nd level minimized
Posterior 2nd level minimized
Posterior 2nd level minimized
Posterior 2nd level minimized
Posterior 2nd level minimized
Checkpoint 4.3: Saving min points for Re done
Posterior 2nd level minimized
Posterior 2nd level minimized
Posterior 2nd level minimized
Posterior 2nd level minimized
Posterior 2nd level minimized
Posterior 2nd level minimized
Posterior 2nd level minimized
Posterior 2nd level minimized
Posterior 2nd level minimized
Posterior 2nd level minimized
Posterior 2nd level minimized
Posterior 2nd level minimized
Posterior 2nd level minimized
Posterior 2nd level minimized
Posterior 2nd level minimized
Checkpoint 4.4: Saving min points for Im done
Checkpoint 5: Integration setup done
NaN detected in the input
tensor([nan, nan, nan], grad_fn=<ViewBackward0>)
NaN detected in the prior
tensor([nan, nan, nan], grad_fn=<ViewBackward0>)
Error in model averaging important sampling for Re z=1a, PDF, jacobi_t kernel lin: torch.linalg.eig: input tensor should not contain infs or NaNs.
NaN detected in the input
tensor([nan, nan, nan], grad_fn=<ViewBackward0>)
NaN detected in the prior
tensor([nan, nan, nan], grad_fn=<ViewBackward0>)
Error in model averaging important sampling for Re z=2a, PDF, jacobi_t kernel lin: torch.linalg.eig: input tensor should not contain infs or NaNs.
NaN detected in the input
tensor([nan, nan, nan], grad_fn=<ViewBackward0>)
NaN detected in the prior
tensor([nan, nan, nan], grad_fn=<ViewBackward0>)
Error in model averaging important sampling for Re z=3a, PDF, jacobi_t kernel lin: torch.linalg.eig: input tensor should not contain infs or NaNs.
NaN detected in the input
tensor([nan, nan, nan], grad_fn=<ViewBackward0>)
NaN detected in the prior
tensor([nan, nan, nan], grad_fn=<ViewBackward0>)
Error in model averaging important sampling for Re z=4a, PDF, jacobi_t kernel lin: torch.linalg.eig: input tensor should not contain infs or NaNs.
NaN detected in the input
tensor([nan, nan, nan], grad_fn=<ViewBackward0>)
NaN detected in the prior
tensor([nan, nan, nan], grad_fn=<ViewBackward0>)
Error in model averaging important sampling for Re z=5a, PDF, jacobi_t kernel lin: torch.linalg.eig: input tensor should not contain infs or NaNs.
NaN detected in the input
tensor([nan, nan, nan], grad_fn=<ViewBackward0>)
NaN detected in the prior
tensor([nan, nan, nan], grad_fn=<ViewBackward0>)
Error in model averaging important sampling for Re z=6a, PDF, jacobi_t kernel lin: torch.linalg.eig: input tensor should not contain infs or NaNs.
NaN detected in the input
tensor([nan, nan, nan], grad_fn=<ViewBackward0>)
NaN detected in the prior
tensor([nan, nan, nan], grad_fn=<ViewBackward0>)
Error in model averaging important sampling for Re z=7a, PDF, jacobi_t kernel lin: torch.linalg.eig: input tensor should not contain infs or NaNs.
Error in model averaging important sampling for Re z=8a, PDF, jacobi_t kernel lin: torch.linalg.eig: input tensor should not contain infs or NaNs.
Error in model averaging important sampling for Im z=7a, PDF, jacobi_t kernel lin: torch.linalg.eig: input tensor should not contain infs or NaNs.
Checkpoint 6: Model averaging gaussian def done
### INITIALIZE MODEL AVERAGING PDF_jacobi_t(Re_kernel) ###
Traceback (most recent call last):
  File "/sciclone/scr-lst/yacahuanamedra/GP/run_IS.py", line 166, in <module>
    data_Re = Modelaveraging_importantsampling_gauss(fits_Re,nn,Nsamp,iB_Re,lista)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sciclone/scr-lst/yacahuanamedra/GP/functions.py", line 160, in Modelaveraging_importantsampling_gauss
    qofx,cov,pms,Qofv,covnu,Qvs=fits_comb[i].model_averaging_IS(2,nn,iB,prob=True,fullevi=True)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/sciclone/scr-lst/yacahuanamedra/GP/GP.py", line 120, in model_averaging_IS
    self.trace_IS=self.dist.sample((10000,))
                  ^^^^^^^^^
AttributeError: 'GaussianProcess' object has no attribute 'dist'
Finished Python at Thu May 29 06:51:11 PM EDT 2025
